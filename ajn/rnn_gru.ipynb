{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with Gater Recurrent Units from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charging data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcess(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.idx2ch = []\n",
    "        self.ch2idx = []\n",
    "    def get_data(self, filename, batch_size=20):\n",
    "        index = 0\n",
    "        self.batch_size = batch_size\n",
    "        with open(filename) as f:\n",
    "            lines = f.read().split('\\n')\n",
    "            raw_data = '\\n'.join(lines)\n",
    "            self.idx2ch = list(set(raw_data))\n",
    "            self.ch2idx = { k:v for v,k in enumerate(self.idx2ch) }\n",
    "\n",
    "        self.n_batches = len(raw_data) // self.batch_size\n",
    "        # create numpy arrays\n",
    "        X = np.zeros([self.n_batches, self.batch_size])\n",
    "        Y = np.zeros([self.n_batches, self.batch_size])\n",
    "        for i in range(0, self.n_batches):\n",
    "            X[i] = np.array([ self.ch2idx[ch] for ch in raw_data[i*self.batch_size:(i+1)*self.batch_size] ])\n",
    "            Y[i] = np.array([ self.ch2idx[ch] for ch in raw_data[(i*self.batch_size) + 1 : ((i+1)*self.batch_size) + 1] ])\n",
    "\n",
    "        return X.astype(np.int32), Y.astype(np.int32)\n",
    "    \n",
    "    def set_parameters(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        return self.n_batches, self.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnn_gru(object):\n",
    "    \n",
    "    def __init__(self, embedding_size, num_classes):\n",
    "        self.loss_arr = []\n",
    "        tf.reset_default_graph()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_classes = num_classes\n",
    "        # Placeholders\n",
    "        xs_ = tf.placeholder(shape=[None, None], dtype=tf.int32)\n",
    "        ys_ = tf.placeholder(shape=[None], dtype=tf.int32)\n",
    "        # Initial state of the network\n",
    "        init_state = tf.placeholder(shape=[None, self.embedding_size], dtype=tf.float32, name='initial_state')\n",
    "        # Embeddings\n",
    "        embs = tf.get_variable('emb', [self.num_classes, self.embedding_size])\n",
    "        rnn_inputs = tf.nn.embedding_lookup(embs, xs_)\n",
    "        # Initializer\n",
    "        xav_init = tf.contrib.layers.xavier_initializer\n",
    "        # Params\n",
    "        self.W = tf.get_variable('W', shape=[3, self.embedding_size, self.embedding_size], initializer=xav_init())\n",
    "        self.U = tf.get_variable('U', shape=[3, self.embedding_size, self.embedding_size], initializer=xav_init())\n",
    "        self.b = tf.get_variable('b', shape=[self.embedding_size], initializer=tf.constant_initializer(0.))\n",
    "        \n",
    "        states = tf.scan(self.step, tf.transpose(rnn_inputs, [1,0,2]), initializer=init_state)\n",
    "        \n",
    "        # Output\n",
    "        V = tf.get_variable('V', shape=[self.embedding_size, self.num_classes], initializer=xav_init())\n",
    "        bo = tf.get_variable('bo', shape=[self.num_classes], initializer=tf.constant_initializer(0.))\n",
    "        states_reshaped = tf.reshape(states, [-1, self.embedding_size])\n",
    "        yPredbyNN = tf.matmul(states_reshaped, V) + bo\n",
    "        predictions = tf.nn.softmax(yPredbyNN)\n",
    "        \n",
    "        # get last state\n",
    "        last_state = states[-1]\n",
    "        \n",
    "        # Optimization\n",
    " \n",
    "        losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = yPredbyNN, labels=ys_)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "    \n",
    "        # Update status\n",
    "        self.xs_ = xs_\n",
    "        self.ys_ = ys_\n",
    "        self.loss = loss\n",
    "        self.train_op = train_op\n",
    "        self.predictions = predictions\n",
    "        self.last_state = last_state\n",
    "        self.init_state = init_state\n",
    "    \n",
    "    def rand_batch_gen(self, x, y, train_batch_size):\n",
    "        while True:\n",
    "            sample_idx = sample(list(np.arange(len(x))), train_batch_size)\n",
    "            yield x[sample_idx], y[sample_idx]\n",
    "    \n",
    "    def step(self, st_1, x):\n",
    "        z = tf.sigmoid(tf.matmul(x,self.U[0]) + tf.matmul(st_1,self.W[0]))\n",
    "        r = tf.sigmoid(tf.matmul(x,self.U[1]) + tf.matmul(st_1,self.W[1]))\n",
    "        h = tf.tanh(tf.matmul(x,self.U[2]) + tf.matmul( (r*st_1),self.W[2]))\n",
    "        st = (1-z)*h + (z*st_1)\n",
    "        return st\n",
    "    \n",
    "    \n",
    "    def train(self, train_set, epochs=50):\n",
    "        # training session\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            train_loss = 0\n",
    "            try:\n",
    "                for i in range(epochs):\n",
    "                    for j in range(1000):\n",
    "                        xs, ys = train_set.__next__()\n",
    "                        batch_size = xs.shape[0]\n",
    "                        _, train_loss_ = sess.run([self.train_op, self.loss], feed_dict = {\n",
    "                                self.xs_ : xs,\n",
    "                                self.ys_ : ys.flatten(),\n",
    "                                self.init_state : np.zeros([batch_size, self.embedding_size])\n",
    "                            })\n",
    "                        train_loss += train_loss_\n",
    "                    self.loss_arr.append(train_loss/1000)\n",
    "                    print('[{}] loss : {}'.format(i,train_loss/1000))\n",
    "                    train_loss = 0\n",
    "            except KeyboardInterrupt:\n",
    "                print('interrupted by user at ' + str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Display differents graphs using different hyperparameters saved in arrays.\n",
    "# Input variables are arrays with the same lenght, with the values to graph\n",
    "\n",
    "def show_graphs(epoch_arr,loss_arr):\n",
    "# define a list of markevery cases to plot\n",
    "    cases=[]\n",
    "    x_values=[]\n",
    "    y_values=[]\n",
    "    for i in range(len(epoch_arr)):\n",
    "        cases.append([epoch_arr[i]])\n",
    "        # define the data for cartesian plots\n",
    "        x_values.append(range(epoch_arr[i]))\n",
    "        y_values.append(loss_arr)\n",
    "    # define the figure size and grid layout properties\n",
    "    figsize = (12, 10)\n",
    "    cols = 2\n",
    "    gs = gridspec.GridSpec(len(cases) // cols + 1, cols)\n",
    "    gs.update(hspace=0.4)\n",
    "    \n",
    "    fig1 = plt.figure(num=1, figsize=figsize)\n",
    "    ax = []\n",
    "    for i, case in enumerate(cases):\n",
    "        row = (i // cols)\n",
    "        col = i % cols\n",
    "        ax.append(fig1.add_subplot(gs[row, col]))\n",
    "        ax[-1].set_title('Epoch=%s' % (str(case[0])))\n",
    "        ax[-1].plot(x_values[i], y_values[i], 'o', ls='-', ms=4, markevery=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] loss : 3.109379982471466\n",
      "[1] loss : 3.1043278386592865\n",
      "[2] loss : 3.1045852324962615\n",
      "[3] loss : 3.1046839780807494\n",
      "[4] loss : 3.1041645150184634\n",
      "[5] loss : 3.1056199281215666\n",
      "[6] loss : 3.106333283185959\n",
      "[7] loss : 3.1058114287853242\n",
      "[8] loss : 3.105020170211792\n",
      "[9] loss : 3.104790813922882\n",
      "[10] loss : 3.1063793568611144\n",
      "[11] loss : 3.1059377274513245\n",
      "[12] loss : 3.106979667663574\n",
      "[13] loss : 3.1051918368339537\n",
      "[14] loss : 3.106333346128464\n",
      "[15] loss : 3.105849818229675\n",
      "[16] loss : 3.1069231069087984\n",
      "[17] loss : 3.119178415298462\n",
      "[18] loss : 3.107190177679062\n",
      "[19] loss : 3.1066489140987397\n",
      "[20] loss : 3.1082334170341492\n",
      "[21] loss : 3.1067325875759124\n",
      "[22] loss : 3.1073607823848723\n",
      "[23] loss : 3.1071897077560426\n",
      "[24] loss : 3.1079471113681794\n",
      "[25] loss : 3.1056616983413696\n",
      "[26] loss : 3.106197536468506\n",
      "[27] loss : 3.106888318300247\n",
      "[28] loss : 3.1064909415245054\n",
      "[29] loss : 3.106295850276947\n",
      "[30] loss : 3.1065077903270724\n",
      "[31] loss : 3.107592219352722\n",
      "[32] loss : 3.107496114015579\n",
      "[33] loss : 3.1078093850612643\n",
      "[34] loss : 3.105862158298492\n",
      "[35] loss : 3.1080535900592805\n",
      "[36] loss : 3.1079194157123564\n",
      "[37] loss : 3.1071441531181336\n",
      "[38] loss : 3.105763028383255\n",
      "[39] loss : 3.1080298976898195\n",
      "[40] loss : 3.105698447227478\n",
      "[41] loss : 3.1080646646022796\n",
      "[42] loss : 3.1064681956768037\n",
      "[43] loss : 3.1074472527503967\n",
      "[44] loss : 3.1071124901771547\n",
      "[45] loss : 3.1073160617351534\n",
      "[46] loss : 3.108667762517929\n",
      "[47] loss : 3.1068030486106872\n",
      "[48] loss : 3.107220652103424\n",
      "[49] loss : 3.1072325763702393\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    BATCH_SIZE = 256 \n",
    "    doc = TextProcess()\n",
    "    x,y = doc.get_data('data/paulg.txt', 20)\n",
    "    embedding_size = x.shape[1]\n",
    "    num_classes = len(doc.idx2ch)\n",
    "    n_batches, data_batch_size = doc.get_parameters()\n",
    "    model = rnn_gru(embedding_size, num_classes)\n",
    "    train_set = model.rand_batch_gen(x,y,BATCH_SIZE)\n",
    "    model.train(train_set)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c714628a7ba5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepoch_arr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mepoch_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mshow_graphs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-1aad00cc80b7>\u001b[0m in \u001b[0;36mshow_graphs\u001b[1;34m(epoch_arr, loss_arr)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Minibatch=%s, Epoch=%s, Learning=%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcase\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcase\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcase\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'o'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarkevery\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_arr=[]\n",
    "epoch_arr.append(50)\n",
    "show_graphs(epoch_arr,model.loss_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
